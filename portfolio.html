<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Samaksh's Portfolio</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Samaksh Judson's Portfolio</h1>
    </header>

    <nav>
        <a href="index.html">Home</a>
        <a href="mailto:judsonsamaksh@gmail.com">Contact</a>
        <a href="https://github.com/Samaksh0278">Github</a>
        <a href="hobbies.html">Hobbies</a>
    </nav>

<section id="KantorLabExperience">
    <h2>Graduate Research Assistant</h2>
    <p><strong>Institution:</strong> Robotics Institute, CMU</p>
    <p><strong>Lab:</strong> Kantor Lab</p>
    <p><strong>Tools Used:</strong> ROS1, ROS2, Docker, Pytorch, C++, Arduino</p>
    <p><strong>Project Timeline:</strong> May 2024 - Aug 2024</p>
    
    <p>
        As a Graduate Research Assistant at the Robotics Institute, I developed a system for <strong>3D point cloud modeling of occluded fruits</strong> in orchards using advanced algorithms and robotic techniques.
    </p>
    
    <ul>
        <li><strong>3D Point Cloud Modeling</strong>: Developed a 3D point cloud system using the <strong>RAFT stereo algorithm</strong> to model occluded fruits in orchard environments, enabling accurate detection even in cluttered scenes.</li>
        <li><strong>Segmentation and Tracking</strong>: Implemented <strong>YOLOv8</strong> for fruit segmentation and enhanced the tracking process with an augmented <strong>DeepSORT algorithm</strong> to maintain tracking consistency across frames.</li>
        <li><strong>Leafblower Actuation System</strong>: Designed and implemented an innovative <strong>leafblower actuation system</strong> controlled via inverse kinematics on servo motors, which cleared obstructions to reveal occluded fruits.</li>
        <li><strong>ROS-Based Docker Deployment</strong>: Deployed the entire solution in a <strong>ROS-based Docker container</strong>, allowing for seamless integration with field robotics systems for real-time orchard monitoring.</li>
        <li><strong>Improvement in Detection Accuracy</strong>: Achieved up to <strong>35% improvement</strong> in occluded fruit detection accuracy compared to baseline models, significantly enhancing the system's performance in practical applications.</li>
    </ul>
    
    <p>
        This project highlights my skills in <strong>computer vision</strong>, <strong>robotics</strong>, and <strong>system integration</strong> for agricultural automation, contributing to advancements in smart farming technologies.
    </p>
</section>


    <section id="Segmentation Project">
    <h2>Segmentation on Open-Source Datasets</h2>
    <p><strong>Tools Used:</strong> Python, Computer Vision</p>
    <p><strong>Project Timeline:</strong> Spring 2024</p>
    
    <p>
        In this project, I worked on improving segmentation performance for complex datasets by developing a 
        <strong>novel diffusion model architecture</strong> to generate labeled synthetic data. This approach helped augment 
        open-source datasets, increasing the size of training data and resulting in an <strong>8% improvement in test accuracy</strong> due to better generalizability.
    </p>
    
    <ul>
        <li><strong>Synthetic Data Generation</strong>: The diffusion model I developed generated high-quality, labeled synthetic data that enhanced the open-source datasets, leading to better model performance during testing.</li>
        <li><strong>Improving Feature Representations</strong>: I focused on refining feature representations, particularly for complex areas such as <strong>hair and facial features</strong> on divergent test data. This improved the classification accuracy for detailed parts.</li>
        <li><strong>Enhanced Object Masks</strong>: By utilizing high-quality object masks, the project also improved the mask quality of the open-source datasets, ensuring better segmentation results.</li>
    </ul>
    
    <p>
        This project highlights my expertise in <strong>computer vision</strong> and <strong>machine learning</strong>, specifically in using advanced architectures to improve model performance through better data augmentation and feature refinement.
    </p>
</section>


    <section id="Optimal Controls for an Autonomous Sailboat">
    <h2>Optimal Control of an Autonomous Sailboat</h2>
    <p><strong>Tools Used:</strong> JULIA, Python, MATLAB</p>
    <p><strong>Project Timeline:</strong> Spring 2024</p>
    
    <p>
        In this project, I developed a <strong>multi-level control system</strong> for an autonomous sailboat. The control system integrated multiple advanced optimization techniques to improve the sailboat's navigation and control in real-world conditions.
    </p>
    
    <ul>
        <li><strong>Route Optimization (RRT*)</strong>: I implemented a global route optimization algorithm, known as Rapidly-exploring Random Trees (RRT*), which helps the sailboat find the most efficient path to its destination while avoiding obstacles in the environment.</li>
        <li><strong>Trajectory Optimization and Model Predictive Control (MPC)</strong>: After determining the global route, I used trajectory optimization and MPC to refine the sailboat's movements, reducing its <strong>navigation error by 15%</strong>. MPC continuously updated the sailboat's path based on current data, ensuring smooth, real-time adjustments to the environment.</li>
        <li><strong>Improving Accuracy</strong>: By using data from the <strong>National Oceanic and Atmospheric Administration (NOAA)</strong>, I tested the system in a real-world scenario and improved the sailboat's accuracy by <strong>20%</strong>.</li>
        <li><strong>Comparison of Techniques</strong>: I also compared two optimization methods, <strong>direct collocation</strong> and <strong>iLQR (Iterative Linear Quadratic Regulator)</strong>, to ensure that the system achieved both accuracy and efficient computation time.</li>
    </ul>

    <p>
        This project demonstrates my ability to apply <strong>control theory</strong> and <strong>optimization techniques</strong> to real-world problems, pushing the limits of what's possible in autonomous navigation systems.
    </p>
</section>

    <section id="I2GROW Project">
    <h2>I2GROW Systems Integration</h2>
    <p><strong>Tools Used:</strong> ROS, Python, SolidWorks, PLC, Mujoco</p>
    <p><strong>Project Timeline:</strong> Fall 2023 - Spring 2024</p>
    
    <p>
        This project involved the development of a <strong>controlled indoor hydroponic agricultural system</strong> designed to siphon household carbon dioxide emissions and optimize plant growth. 
        I implemented an advanced sensor pipeline in ROS to monitor environmental conditions and improve plant health.
    </p>
    
    <ul>
        <li><strong>Hydroponic System</strong>: Designed and implemented a fully controlled indoor hydroponic system that absorbs CO₂ emissions from households, helping reduce carbon footprint while promoting plant growth.</li>
        <li><strong>Digital Twin of Lettuce Plants</strong>: Created a digital twin of lettuce plants using the <strong>NiCoLet model</strong>, allowing us to predict plant growth with high accuracy (88%). The model was trained on real-time environment data collected through a sensor pipeline integrated with ROS.</li>
    </ul>
    
    <p>
        This project showcases my ability to integrate <strong>mechanical design</strong> and <strong>sensor technologies</strong> with <strong>ROS</strong> for real-world agricultural applications, bridging the gap between environmental sustainability and technology.
    </p>
</section>


   <section id="PathPlanning Project">
    <h2>Imperative Path Planning</h2>
    <p><strong>Tools Used:</strong> Python, ROS, Isaac Sim</p>
    <p><strong>Project Timeline:</strong> Fall 2023</p>
    
    <p>
        This project involved the development of a novel <strong>unsupervised learning approach</strong> to train a path planning policy for robot perception and navigation. The goal was to enhance the robot's ability to navigate complex environments with minimal data.
    </p>
    
    <ul>
        <li><strong>Unsupervised Path Planning</strong>: Designed and implemented an unsupervised learning method to train a robot's path planning policy, significantly improving its perception and navigation capabilities without requiring large labeled datasets.</li>
        <li><strong>Bi-level Trajectory Optimization</strong>: Addressed the limitations of conventional unsupervised learning techniques by employing a bi-level trajectory optimization strategy, achieving state-of-the-art (SOTA) performance in <strong>zero-shot obstacle avoidance</strong> and <strong>waypoint generation</strong>.</li>
    </ul>
    
    <p>
        This project demonstrates my expertise in <strong>robotic navigation</strong> and <strong>unsupervised learning</strong>, showing how advanced optimization techniques can enhance a robot's ability to navigate and avoid obstacles in real-time.
    </p>
</section>


<section id="CrackDetection Project">
    <h2>Wheeled Locomotive for Crack Detection</h2>
    <p><strong>Department:</strong> Computer Science Department, BITS Pilani, India</p>
    <p><strong>Tools Used:</strong> ROS, Open3D, Webots, Python</p>
    <p><strong>Project Timeline:</strong> Fall 2021</p>
    
    <p>
        This project focused on designing and modeling a <strong>non-holonomic four-wheeled automotive</strong> system with advanced feedback-based control for detecting cracks in infrastructure. The system used advanced sensors and point cloud analysis for crack depth estimation and structural integrity evaluation.
    </p>
    
    <ul>
        <li><strong>Vehicle Design and Control</strong>: Designed and modeled a non-holonomic four-wheeled vehicle equipped with feedback-based control systems for precise maneuvering and navigation.</li>
        <li><strong>Localization Using EKF</strong>: Developed a custom ROS wrapper to integrate the <strong>Extended Kalman Filter (EKF)</strong> for precise localization, ensuring accurate detection of infrastructure cracks.</li>
        <li><strong>LiDAR Integration and Point Cloud Analysis</strong>: Integrated LiDAR with the vehicle and utilized <strong>Open3D</strong> to create 3D point clouds, enabling the system to estimate crack depth and assess structural integrity.</li>
    </ul>
    
    <p>
        This project demonstrates my expertise in <strong>robotic localization</strong>, <strong>sensor integration</strong>, and <strong>point cloud analysis</strong> for real-world infrastructure monitoring applications.
    </p>
</section>


    <section id="contact">
        <h2>Contact</h2>
        <p>Email me at: <a href="mailto:judsonsamaksh@gmail.com">judsonsamaksh@gmail.com</a></p>
        <p>Personal Phone - (412) 251-8579</p>
    </section>

    <footer>
        <p>© 2024 Samaksh Judson. All Rights Reserved.</p>
    </footer>
</body>
</html>
